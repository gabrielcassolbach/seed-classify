#!/usr/bin/env python

import cv2
import os
import sys
import getopt
from edge_impulse_linux.image import ImageImpulseRunner

runner = None

def help():
    print('Uso: python classify_camera.py <path_to_model.eim>')

def main(argv):
    try:
        opts, args = getopt.getopt(argv, "h", ["--help"])
    except getopt.GetoptError:
        help()
        sys.exit(2)

    for opt, arg in opts:
        if opt in ('-h', '--help'):
            help()
            sys.exit()

    if len(args) != 1:
        help()
        sys.exit(2)

    model = args[0]
    dir_path = os.path.dirname(os.path.realpath(__file__))
    modelfile = os.path.join(dir_path, model)

    print('MODEL: ' + modelfile)

    # Configuração da câmera
    camera_index = 1  # Ajuste se necessário
    cam = cv2.VideoCapture(camera_index)
    if not cam.isOpened():
        print("Erro ao abrir a câmera.")
        sys.exit(1)

    with ImageImpulseRunner(modelfile) as runner:
        try:
            model_info = runner.init()
            print('Modelo carregado: "' + model_info['project']['owner'] + ' / ' + model_info['project']['name'] + '"')
            labels = model_info['model_parameters']['labels']

            # Captura a imagem da câmera
            ret, image = cam.read()
            if not ret:
                print("Erro ao capturar a imagem da câmera.")
                sys.exit(1)

            # Converte a imagem para RGB
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Extrai as features da imagem
            features, cropped = runner.get_features_from_image_auto_studio_setings(image)

            # Classifica a imagem usando o modelo do Edge Impulse
            res = runner.classify(features)

            if "classification" in res["result"].keys():
                print('Resultado (%d ms.) ' % (res['timing']['dsp'] + res['timing']['classification']), end='')
                for label in labels:
                    score = res['result']['classification'][label]
                    print('%s: %.2f\t' % (label, score), end='')
                print('', flush=True)

            elif "bounding_boxes" in res["result"].keys():
                print('Encontrados %d bounding boxes (%d ms.)' % (len(res["result"]["bounding_boxes"]), res['timing']['dsp'] + res['timing']['classification']))
                for bb in res["result"]["bounding_boxes"]:
                    print('\t%s (%.2f): x=%d y=%d w=%d h=%d' % (bb['label'], bb['value'], bb['x'], bb['y'], bb['width'], bb['height']))
                    cropped = cv2.rectangle(cropped, (bb['x'], bb['y']), (bb['x'] + bb['width'], bb['y'] + bb['height']), (255, 0, 0), 1)

            if "visual_anomaly_grid" in res["result"].keys():
                print('Encontradas %d anomalias visuais (%d ms.)' % (len(res["result"]["visual_anomaly_grid"]), res['timing']['dsp'] + res['timing']['classification']))
                for grid_cell in res["result"]["visual_anomaly_grid"]:
                    print('\t%s (%.2f): x=%d y=%d w=%d h=%d' % (grid_cell['label'], grid_cell['value'], grid_cell['x'], grid_cell['y'], grid_cell['width'], grid_cell['height']))
                    cropped = cv2.rectangle(cropped, (grid_cell['x'], grid_cell['y']), (grid_cell['x'] + grid_cell['width'], grid_cell['y'] + grid_cell['height']), (255, 125, 0), 1)
                values = [grid_cell['value'] for grid_cell in res["result"]["visual_anomaly_grid"]]
                mean_value = sum(values) / len(values)
                max_value = max(values)
                print('Max value: %.2f' % max_value)
                print('Mean value: %.2f' % mean_value)

            # Salva a imagem processada para depuração
            cv2.imwrite('captured_image.jpg', cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR))
            print("Imagem capturada e salva como captured_image.jpg")

        finally:
            if runner:
                runner.stop()
            cam.release()

if __name__ == "__main__":
   main(sys.argv[1:])
